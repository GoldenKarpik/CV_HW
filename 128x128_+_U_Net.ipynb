{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDrPhZMHz5WO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyImageNetDataset(Dataset):\n",
        "    def __init__(self, root_dir, class_names=None, split='train', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(os.path.join(root_dir, 'wnids.txt'), 'r') as f:\n",
        "            all_class_names = [line.strip() for line in f]\n",
        "\n",
        "        if class_names is None:\n",
        "            class_names = all_class_names\n",
        "        self.class_names = class_names\n",
        "        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}\n",
        "        self.samples = self._make_dataset()\n",
        "        print(f'{split}: {len(self.samples)} изображений, {len(self.class_names)} классов')\n",
        "\n",
        "    def _make_dataset(self):\n",
        "        data = []\n",
        "        if self.split == 'train':\n",
        "            train_dir = os.path.join(self.root_dir, 'train')\n",
        "            for cls_name in self.class_names:\n",
        "                img_dir = os.path.join(train_dir, cls_name, 'images')\n",
        "                if not os.path.exists(img_dir):\n",
        "                    continue\n",
        "                for img_name in os.listdir(img_dir):\n",
        "                    img_path = os.path.join(img_dir, img_name)\n",
        "                    label = self.class_to_idx[cls_name]\n",
        "                    data.append((img_path, label))\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "class MoonSegmentationDataset(Dataset):\n",
        "    def __init__(self, root_dir, image_ids=None, augmentation=None, preprocessing=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "        images_dir = os.path.join(root_dir, 'images', 'render')\n",
        "        if image_ids is None:\n",
        "            all_images = os.listdir(images_dir)\n",
        "            self.image_ids = [img.replace('.png', '') for img in all_images if img.endswith('.png')]\n",
        "        else:\n",
        "            self.image_ids = image_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.image_ids[idx]\n",
        "        image_path = os.path.join(self.root_dir, 'images', 'render', f'{image_id}.png')\n",
        "        mask_id = image_id.replace('render', '') if 'render' in image_id else image_id\n",
        "        mask_path = os.path.join(self.root_dir, 'images', 'ground', f'ground{mask_id}.png')\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = (mask > 0).astype(np.float32)\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "H8XWNn9XNP_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, features=[16, 32, 64, 128]):\n",
        "        super().__init__()\n",
        "        self.encoder_blocks = nn.ModuleList()\n",
        "        self.decoder_blocks = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        prev_channels = in_channels\n",
        "        for feature in features:\n",
        "            self.encoder_blocks.append(DoubleConv(prev_channels, feature))\n",
        "            prev_channels = feature\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
        "        for feature in reversed(features):\n",
        "            self.decoder_blocks.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
        "            self.decoder_blocks.append(DoubleConv(feature * 2, feature))\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        for idx in range(0, len(self.decoder_blocks), 2):\n",
        "            x = self.decoder_blocks[idx](x)\n",
        "            skip_connection = skip_connections[idx // 2]\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = F.interpolate(x, size=skip_connection.shape[2:], mode='bilinear', align_corners=True)\n",
        "            x = torch.cat([skip_connection, x], dim=1)\n",
        "            x = self.decoder_blocks[idx + 1](x)\n",
        "        return self.final_conv(x)\n",
        "\n",
        "class UNetWithBackbone(nn.Module):\n",
        "    def __init__(self, backbone, out_channels=1):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.decoder4 = DoubleConv(512 + 512, 512)\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.decoder3 = DoubleConv(256 + 256, 256)\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.decoder2 = DoubleConv(128 + 128, 128)\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.decoder1 = DoubleConv(64 + 64, 64)\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = F.relu(self.backbone.bn1(self.backbone.conv1(x)))\n",
        "        x = self.backbone.pool(enc1)\n",
        "        enc2 = F.relu(self.backbone.bn2(self.backbone.conv2(x)))\n",
        "        x = self.backbone.pool(enc2)\n",
        "        enc3 = F.relu(self.backbone.bn3(self.backbone.conv3(x)))\n",
        "        x = self.backbone.pool(enc3)\n",
        "        enc4 = F.relu(self.backbone.bn4(self.backbone.conv4(x)))\n",
        "        x = self.backbone.pool(enc4)\n",
        "        bottleneck = self.bottleneck(x)\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = self.decoder4(torch.cat([dec4, enc4], dim=1))\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = self.decoder3(torch.cat([dec3, enc3], dim=1))\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = self.decoder2(torch.cat([dec2, enc2], dim=1))\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = self.decoder1(torch.cat([dec1, enc1], dim=1))\n",
        "        return self.final_conv(dec1)"
      ],
      "metadata": {
        "id": "PP071e7vNSYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# метрики\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        predictions = torch.sigmoid(predictions)\n",
        "        predictions = predictions.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (predictions * targets).sum()\n",
        "        dice = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
        "        return 1 - dice\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.dice_weight = dice_weight\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.dice = DiceLoss()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        bce_loss = self.bce(predictions, targets)\n",
        "        dice_loss = self.dice(predictions, targets)\n",
        "        return self.bce_weight * bce_loss + self.dice_weight * dice_loss\n",
        "\n",
        "def dice_coefficient(predictions, targets, threshold=0.5, smooth=1e-6):\n",
        "    predictions = torch.sigmoid(predictions)\n",
        "    predictions = (predictions > threshold).float()\n",
        "    predictions = predictions.view(-1)\n",
        "    targets = targets.view(-1)\n",
        "    intersection = (predictions * targets).sum()\n",
        "    dice = (2. * intersection + smooth) / (predictions.sum() + targets.sum() + smooth)\n",
        "    return dice.item()\n",
        "\n",
        "def iou_score(predictions, targets, threshold=0.5, smooth=1e-6):\n",
        "    predictions = torch.sigmoid(predictions)\n",
        "    predictions = (predictions > threshold).float()\n",
        "    predictions = predictions.view(-1)\n",
        "    targets = targets.view(-1)\n",
        "    intersection = (predictions * targets).sum()\n",
        "    union = predictions.sum() + targets.sum() - intersection\n",
        "    iou = (intersection + smooth) / (union + smooth)\n",
        "    return iou.item()\n",
        "\n",
        "def pixel_accuracy(predictions, targets, threshold=0.5):\n",
        "    predictions = torch.sigmoid(predictions)\n",
        "    predictions = (predictions > threshold).float()\n",
        "    correct = (predictions == targets).float().sum()\n",
        "    total = targets.numel()\n",
        "    return (correct / total).item()"
      ],
      "metadata": {
        "id": "X-gQNKFlNZe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch_segmentation(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_dice = 0.0\n",
        "    running_iou = 0.0\n",
        "    pbar = tqdm(loader, desc='обучение')\n",
        "    for images, masks in pbar:\n",
        "        images = images.to(device)\n",
        "        masks = masks.unsqueeze(1).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            dice = dice_coefficient(outputs, masks)\n",
        "            iou = iou_score(outputs, masks)\n",
        "        running_loss += loss.item()\n",
        "        running_dice += dice\n",
        "        running_iou += iou\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'dice': f'{dice:.4f}', 'iou': f'{iou:.4f}'})\n",
        "    return running_loss / len(loader), running_dice / len(loader), running_iou / len(loader)\n",
        "\n",
        "def validate_epoch_segmentation(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_dice = 0.0\n",
        "    running_iou = 0.0\n",
        "    running_acc = 0.0\n",
        "    pbar = tqdm(loader, desc='валидация')\n",
        "    with torch.no_grad():\n",
        "        for images, masks in pbar:\n",
        "            images = images.to(device)\n",
        "            masks = masks.unsqueeze(1).to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            dice = dice_coefficient(outputs, masks)\n",
        "            iou = iou_score(outputs, masks)\n",
        "            acc = pixel_accuracy(outputs, masks)\n",
        "            running_loss += loss.item()\n",
        "            running_dice += dice\n",
        "            running_iou += iou\n",
        "            running_acc += acc\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'dice': f'{dice:.4f}', 'iou': f'{iou:.4f}', 'acc': f'{acc:.4f}'})\n",
        "    return running_loss / len(loader), running_dice / len(loader), running_iou / len(loader), running_acc / len(loader)\n",
        "\n",
        "def train_model_segmentation(model, train_loader, val_loader, optimizer, criterion, scheduler, device, num_epochs=20, save_path='best_unet.pth'):\n",
        "    model = model.to(device)\n",
        "    history = {'train_loss': [], 'train_dice': [], 'train_iou': [], 'val_loss': [], 'val_dice': [], 'val_iou': [], 'val_acc': []}\n",
        "    best_val_dice = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'эпоха {epoch + 1}/{num_epochs}')\n",
        "        train_loss, train_dice, train_iou = train_epoch_segmentation(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_dice, val_iou, val_acc = validate_epoch_segmentation(model, val_loader, criterion, device)\n",
        "        history['train_loss'].append(train_loss); history['train_dice'].append(train_dice); history['train_iou'].append(train_iou)\n",
        "        history['val_loss'].append(val_loss); history['val_dice'].append(val_dice); history['val_iou'].append(val_iou)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        if scheduler:\n",
        "            scheduler.step(val_dice)\n",
        "        print(f'  train - loss: {train_loss:.4f}, dice: {train_dice:.4f}, iou: {train_iou:.4f}')\n",
        "        print(f'  val   - loss: {val_loss:.4f}, dice: {val_dice:.4f}, iou: {val_iou:.4f}, acc: {val_acc:.4f}')\n",
        "        if val_dice > best_val_dice:\n",
        "            best_val_dice = val_dice\n",
        "            torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'val_dice': val_dice, 'val_iou': val_iou}, save_path)\n",
        "            print(f'лучшая модель с dice: {val_dice:.4f}')\n",
        "    print(f'лучший val dice: {best_val_dice:.4f}')\n",
        "    return history"
      ],
      "metadata": {
        "id": "CKdilXiKNfrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# визуализация\n",
        "def denormalize(img_tensor):\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    img = img_tensor * std + mean\n",
        "    return img.clamp(0, 1)\n",
        "\n",
        "def plot_segmentation_history(history):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    axes[0, 0].plot(history['train_loss'], label='train loss', color='blue', linewidth=2)\n",
        "    axes[0, 0].plot(history['val_loss'], label='val loss', color='red', linewidth=2)\n",
        "    axes[0, 0].set_title('loss'); axes[0, 0].set_xlabel('эпоха'); axes[0, 0].set_ylabel('loss')\n",
        "    axes[0, 0].legend(); axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[0, 1].plot(history['train_dice'], label='train dice', color='blue', linewidth=2)\n",
        "    axes[0, 1].plot(history['val_dice'], label='val dice', color='red', linewidth=2)\n",
        "    axes[0, 1].set_title('dice coefficient'); axes[0, 1].set_xlabel('эпоха'); axes[0, 1].set_ylabel('dice')\n",
        "    axes[0, 1].legend(); axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1, 0].plot(history['train_iou'], label='train iou', color='blue', linewidth=2)\n",
        "    axes[1, 0].plot(history['val_iou'], label='val iou', color='red', linewidth=2)\n",
        "    axes[1, 0].set_title('iou score'); axes[1, 0].set_xlabel('эпоха'); axes[1, 0].set_ylabel('iou')\n",
        "    axes[1, 0].legend(); axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1, 1].plot(history['val_acc'], label='val acc', color='red', linewidth=2)\n",
        "    axes[1, 1].set_title('pixel accuracy'); axes[1, 1].set_xlabel('эпоха'); axes[1, 1].set_ylabel('accuracy')\n",
        "    axes[1, 1].legend(); axes[1, 1].grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def visualize_segmentation_predictions(model, loader, device, num_samples=5):\n",
        "    model.eval()\n",
        "    images, masks = next(iter(loader))\n",
        "    images = images.to(device)\n",
        "    masks = masks.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        predictions = torch.sigmoid(outputs)\n",
        "        predictions = (predictions > 0.5).float()\n",
        "    images = images.cpu()\n",
        "    predictions = predictions.cpu()\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4 * num_samples))\n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        img = denormalize(images[i]).permute(1, 2, 0).numpy()\n",
        "        mask_true = masks[i].cpu().numpy()\n",
        "        mask_pred = predictions[i, 0].numpy()\n",
        "\n",
        "        axes[i, 0].imshow(img)\n",
        "        axes[i, 0].set_title('исходное изображение')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(mask_true, cmap='gray')\n",
        "        axes[i, 1].set_title('истинная маска')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        dice_val = dice_coefficient(outputs[i:i + 1], masks[i:i + 1].unsqueeze(1))\n",
        "        iou_val = iou_score(outputs[i:i + 1], masks[i:i + 1].unsqueeze(1))\n",
        "        axes[i, 2].imshow(mask_pred, cmap='gray')\n",
        "        axes[i, 2].set_title(f'предсказание\\ndice: {dice_val:.3f}, iou: {iou_val:.3f}')\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "        overlay = img.copy()\n",
        "        overlay[mask_pred > 0.5] = [0, 1, 0]\n",
        "        axes[i, 3].imshow(overlay)\n",
        "        axes[i, 3].set_title('наложение')\n",
        "        axes[i, 3].axis('off')\n",
        "    plt.suptitle('предсказания модели u-net', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dxT1_oRNNoBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSIFICATION_DATA = \"tiny-imagenet-200\"\n",
        "SEGMENTATION_DATA = \"MOON_SEGMENTATION_BINARY\"\n",
        "\n",
        "# классификация\n",
        "with open(os.path.join(CLASSIFICATION_DATA, 'wnids.txt'), 'r') as f:\n",
        "    all_class_names = [line.strip() for line in f]\n",
        "selected_classes = all_class_names[:20]\n",
        "\n",
        "train_transform_class = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "val_transform_class = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# сегментация\n",
        "train_aug_seg = A.Compose([\n",
        "    A.Resize(128, 128),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.Affine(translate_percent=0.1, scale=0.1, rotate=45, p=0.5),\n",
        "    A.OneOf([A.GaussNoise(var_limit=(10.0, 50.0)), A.GaussianBlur(blur_limit=(3, 7))], p=0.3),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "])\n",
        "val_aug_seg = A.Compose([A.Resize(128, 128)])\n",
        "preprocessing_seg = A.Compose([\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2(),\n",
        "])"
      ],
      "metadata": {
        "id": "lsFk3l3aNwx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обучение класификатора\n",
        "full_dataset = TinyImageNetDataset(CLASSIFICATION_DATA, selected_classes, split='train', transform=train_transform_class)\n",
        "all_labels = [lbl for _, lbl in full_dataset.samples]\n",
        "train_idx, val_idx = train_test_split(range(len(full_dataset)), test_size=0.2, stratify=all_labels, random_state=42)\n",
        "train_dataset_class = torch.utils.data.Subset(full_dataset, train_idx)\n",
        "val_dataset_class = torch.utils.data.Subset(TinyImageNetDataset(CLASSIFICATION_DATA, selected_classes, split='train', transform=val_transform_class), val_idx)\n",
        "\n",
        "train_loader_class = DataLoader(train_dataset_class, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader_class = DataLoader(val_dataset_class, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "classifier = SimpleCNN(num_classes=len(selected_classes)).to(device)\n",
        "optimizer_class = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "criterion_class = nn.CrossEntropyLoss()\n",
        "\n",
        "history_class = train_model_classification(classifier, train_loader_class, val_loader_class, optimizer_class, criterion_class, device, num_epochs=3)\n",
        "plot_classification_history(history_class)"
      ],
      "metadata": {
        "id": "jiK9qJbbN3LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# базовая unet\n",
        "images_dir = os.path.join(SEGMENTATION_DATA, 'images', 'render')\n",
        "all_images = [img.replace('.png', '') for img in os.listdir(images_dir) if img.endswith('.png')]\n",
        "train_ids, val_ids = train_test_split(all_images, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset_seg = MoonSegmentationDataset(SEGMENTATION_DATA, image_ids=train_ids, augmentation=train_aug_seg, preprocessing=preprocessing_seg)\n",
        "val_dataset_seg = MoonSegmentationDataset(SEGMENTATION_DATA, image_ids=val_ids, augmentation=val_aug_seg, preprocessing=preprocessing_seg)\n",
        "\n",
        "train_loader_seg = DataLoader(train_dataset_seg, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader_seg = DataLoader(val_dataset_seg, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "unet = UNet(in_channels=3, out_channels=1, features=[16, 32, 64, 128]).to(device)\n",
        "optimizer_unet = torch.optim.Adam(unet.parameters(), lr=1e-3)\n",
        "criterion_unet = CombinedLoss(bce_weight=0.5, dice_weight=0.5)\n",
        "scheduler_unet = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_unet, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "history_unet = train_model_segmentation(unet, train_loader_seg, val_loader_seg, optimizer_unet, criterion_unet, scheduler_unet, device, num_epochs=3, save_path='best_unet.pth')\n",
        "plot_segmentation_history(history_unet)\n",
        "visualize_segmentation_predictions(unet, val_loader_seg, device)"
      ],
      "metadata": {
        "id": "N-rHARYSN751"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unet с замороженным бэкбоном\n",
        "backbone_frozen = SimpleCNN(num_classes=len(selected_classes))\n",
        "backbone_frozen.load_state_dict(torch.load('models/best_classifier.pth', map_location='cpu', weights_only=False))\n",
        "unet_frozen = UNetWithBackbone(backbone_frozen, out_channels=1).to(device)\n",
        "\n",
        "for param in unet_frozen.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "optimizer_frozen = torch.optim.Adam(filter(lambda p: p.requires_grad, unet_frozen.parameters()), lr=1e-3)\n",
        "\n",
        "history_frozen = train_model_segmentation(unet_frozen, train_loader_seg, val_loader_seg, optimizer_frozen, criterion_unet, None, device, num_epochs=3, save_path='best_unet_frozen.pth')\n",
        "plot_segmentation_history(history_frozen)"
      ],
      "metadata": {
        "id": "vCEh4h8PN-ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unet с размороженным бэкбоном\n",
        "backbone_unfrozen = SimpleCNN(num_classes=len(selected_classes))\n",
        "backbone_unfrozen.load_state_dict(torch.load('models/best_classifier.pth', map_location='cpu', weights_only=False))\n",
        "unet_unfrozen = UNetWithBackbone(backbone_unfrozen, out_channels=1).to(device)\n",
        "\n",
        "backbone_params = []\n",
        "decoder_params = []\n",
        "for name, param in unet_unfrozen.named_parameters():\n",
        "    if 'backbone' in name:\n",
        "        backbone_params.append(param)\n",
        "    else:\n",
        "        decoder_params.append(param)\n",
        "\n",
        "optimizer_unfrozen = torch.optim.Adam([\n",
        "    {'params': backbone_params, 'lr': 1e-4},\n",
        "    {'params': decoder_params, 'lr': 1e-3}\n",
        "])\n",
        "scheduler_unfrozen = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_unfrozen, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "history_unfrozen = train_model_segmentation(unet_unfrozen, train_loader_seg, val_loader_seg, optimizer_unfrozen, criterion_unet, scheduler_unfrozen, device, num_epochs=3, save_path='best_unet_unfrozen.pth')\n",
        "plot_segmentation_history(history_unfrozen)"
      ],
      "metadata": {
        "id": "bq1Jpgc7OEXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}